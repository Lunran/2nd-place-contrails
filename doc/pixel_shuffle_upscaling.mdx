# ピクセルシャッフルアップスケーリング (Pixel Shuffle Upscaling)

## 概要
ピクセルシャッフルアップスケーリング（Pixel Shuffle Upscaling）は、深層学習における効率的な画像解像度向上手法である。従来の転置畳み込み（transpose convolution）や補間による手法と比較して、計算効率性と品質の両面で優れた特性を持つ。

## 技術的原理

### 基本概念
ピクセルシャッフルは、チャンネル次元の情報を空間次元に再配置することで画像の解像度を向上させる技術である。具体的には、入力テンソル `(B, C×r², H, W)` を `(B, C, H×r, W×r)` に変換する操作を行う（ここで `r` はスケールファクター）。

### 具体例による動作説明

#### 数値例1: スケールファクター2での基本動作
入力テンソル: `(1, 4, 2, 2)` → 出力テンソル: `(1, 1, 4, 4)`

```
入力（チャンネル数=4, サイズ=2×2）:
チャンネル0: [[1, 2],    チャンネル1: [[5, 6],
              [3, 4]]                   [7, 8]]

チャンネル2: [[9, 10],   チャンネル3: [[13, 14],
              [11, 12]]                  [15, 16]]

↓ PixelShuffle(scale=2)

出力（チャンネル数=1, サイズ=4×4）:
[[1,  5,  2,  6],
 [9,  13, 10, 14],
 [3,  7,  4,  8],
 [11, 15, 12, 16]]
```

#### 数値例2: UnetBlockでの実際の使用例
```python
# 入力: up_in_c=256, 出力解像度を2倍に
# PixelShuffle_ICNR(256, 128, scale=2)

# ステップ1: 1×1畳み込みでチャンネル数を4倍に拡張
# (B, 256, H, W) → (B, 512, H, W)  # 512 = 128 * 2²

# ステップ2: PixelShuffleで空間解像度を2倍に
# (B, 512, H, W) → (B, 128, 2H, 2W)

# 実際の変換例（H=32, W=32の場合）:
# (1, 256, 32, 32) → (1, 512, 32, 32) → (1, 128, 64, 64)
```

#### 数値例3: チェッカーボードパターンの抑制
```
従来の転置畳み込み（チェッカーボード発生）:
[[1, 0, 2, 0],    vs    ICNR初期化済みPixelShuffle:
 [0, 0, 0, 0],          [[1, 1.5, 2, 2.5],
 [3, 0, 4, 0],           [1.5, 2, 2.5, 3],
 [0, 0, 0, 0]]           [3, 3.5, 4, 4.5],
                         [3.5, 4, 4.5, 5]]
```

### 実装詳細
本コードベースでは `PixelShuffle_ICNR` クラスとして実装されている：

```python
class PixelShuffle_ICNR(nn.Sequential):
    def __init__(self, ni, nf=None, scale=2, blur=True):
        super().__init__()
        nf = ni if nf is None else nf
        layers = [nn.Conv2d(ni, nf*(scale**2), 1), LayerNorm2d(nf*(scale**2)), 
                  nn.GELU(), nn.PixelShuffle(scale)]
        layers[0].weight.data.copy_(icnr_init(layers[0].weight.data))
        if blur: layers += [nn.ReplicationPad2d((1,0,1,0)), nn.AvgPool2d(2, stride=1)]
        super().__init__(*layers)
```

### ICNR初期化 (Improved Checkerboard Reduction Normalization)

#### 概要と目的
ICNR（Improved Checkerboard Reduction Normalization）は、ピクセルシャッフルにおけるチェッカーボードアーティファクト（市松模様状のノイズ）を抑制するための重み初期化手法である。従来のピクセルシャッフルでは、ランダムな重み初期化により不規則なパターンが生成され、視覚的品質が劣化する問題があった。

#### 技術的原理
ICNRは、各sub-pixel位置に対して同一の初期カーネルを複製することで、滑らかなアップサンプリングを実現する。具体的には、`scale²` 個のsub-pixelチャンネルに対して、同じカーネルパターンを繰り返し配置する。

```python
def icnr_init(x, scale=2, init=nn.init.kaiming_normal_):
    "ICNR init of `x`, with `scale` and `init` function"
    ni,nf,h,w = x.shape
    ni2 = int(ni/(scale**2))  # 元のチャンネル数
    k = init(x.new_zeros([ni2,nf,h,w])).transpose(0, 1)  # 基本カーネル生成
    k = k.contiguous().view(ni2, nf, -1)
    k = k.repeat(1, 1, scale**2)  # scale²回複製
    return k.contiguous().view([nf,ni,h,w]).transpose(0, 1)
```

#### 動作メカニズムの詳細

1. **基本カーネル生成**: 元の出力チャンネル数 `nf` に対して `ni2 = ni/(scale²)` 個の基本カーネルを生成
2. **カーネル複製**: 各基本カーネルを `scale²` 回複製して、全sub-pixel位置に同一パターンを配置
3. **テンソル再構成**: 複製されたカーネルを適切な形状に再配置

#### ICNR初期化の具体的な数値例

以下は `scale=2, ni=8, nf=2, h=1, w=1` の場合の詳細な処理過程：

```python
# 初期パラメータ
# x.shape = (8, 2, 1, 1)  # 入力重みテンソル
# scale = 2, ni = 8, nf = 2, h = 1, w = 1
# ni2 = 8 / (2²) = 2

# ステップ1: 基本カーネル生成
k = init(x.new_zeros([2, 2, 1, 1]))  # shape: (2, 2, 1, 1)

# 【重要】基本カーネルの決定方法と意味:
# - init関数（通常はkaiming_normal_）により統計的に適切な値を生成
# - 各基本カーネルは独立した特徴検出器として機能
# - 例: 以下の値が生成されたとする（実際の値は確率的に決定）
k = tensor([[[[0.5]], [[0.3]]],    # 基本カーネル0: 入力ch0→出力ch0,1
            [[[0.8]], [[0.6]]]])   # 基本カーネル1: 入力ch1→出力ch0,1

# 【チェッカーノイズ抑制の原理】
# 問題: ランダム初期化では、隣接するsub-pixel位置で異なる重みが使用される
# 例えば、ランダム初期化の場合:
# 位置(0,0)の重み: [0.2, 0.9]  位置(0,1)の重み: [0.7, 0.1]  ← 大きな差
# 位置(1,0)の重み: [0.8, 0.3]  位置(1,1)の重み: [0.1, 0.6]  ← 不連続

# 解決策: ICNRでは同じ基本パターンを全sub-pixel位置で使用
# すべての位置で一貫した重み: [0.5, 0.3] または [0.8, 0.6]
# → 隣接ピクセル間の急激な変化を防止

# ステップ2: transpose(0, 1)で軸を交換
k = k.transpose(0, 1)  # shape: (2, 2, 1, 1)
k = tensor([[[[0.5]], [[0.8]]],    # 出力チャンネル0向け: [基本0, 基本1]
            [[[0.3]], [[0.6]]]])   # 出力チャンネル1向け: [基本0, 基本1]

# ステップ3: view操作でテンソルを平坦化
k = k.contiguous().view(2, 2, -1)  # shape: (2, 2, 1)
k = tensor([[[0.5], [0.8]],        # 出力チャンネル0向け
            [[0.3], [0.6]]])       # 出力チャンネル1向け

# ステップ4: repeat(1, 1, scale²)でsub-pixel分複製
# 【核心】ここで各基本パターンをscale²回複製することで統一性を確保
k = k.repeat(1, 1, 4)  # scale² = 4回複製, shape: (2, 2, 4)
k = tensor([[[0.5, 0.5, 0.5, 0.5], [0.8, 0.8, 0.8, 0.8]],  # 全位置で同じ値
            [[0.3, 0.3, 0.3, 0.3], [0.6, 0.6, 0.6, 0.6]]])  # 全位置で同じ値

# ステップ5: 最終形状への再構成
k = k.contiguous().view([2, 8, 1, 1])  # shape: (2, 8, 1, 1)
k = tensor([[[[0.5]], [[0.8]], [[0.5]], [[0.8]],    # 出力ch0: パターン[0.5,0.8]反復
             [[0.5]], [[0.8]], [[0.5]], [[0.8]]],
            [[[0.3]], [[0.6]], [[0.3]], [[0.6]],    # 出力ch1: パターン[0.3,0.6]反復  
             [[0.3]], [[0.6]], [[0.3]], [[0.6]]]])

# ステップ6: transpose(0, 1)で最終形状に
result = k.transpose(0, 1)  # shape: (8, 2, 1, 1)
```

#### なぜチェッカーボードノイズが抑制されるのか

**1. 問題の根本原因**
```python
# ランダム初期化の場合（問題のあるケース）:
# 入力: (B, 4, H, W) → PixelShuffle → 出力: (B, 1, 2H, 2W)

# 各sub-pixel位置で異なる重みが使用される:
weights_random = [
    [0.2, 0.7, 0.1, 0.9],  # 位置ごとにランダムな重み
    # ↓ PixelShuffle後の配置
    # [0.2  0.7]  ← 隣接する値の差が大きい (0.7-0.2=0.5)
    # [0.1  0.9]  ← 対角線上でも大きな差 (0.9-0.1=0.8)
]
# 結果: 市松模様状のアーティファクト発生
```

**2. ICNRによる解決**
```python
# ICNR初期化の場合（改善されたケース）:
# 基本カーネル: [0.5, 0.8] が全位置で使用される

weights_icnr = [
    [0.5, 0.8, 0.5, 0.8],  # 同じパターンの繰り返し
    # ↓ PixelShuffle後の配置  
    # [0.5  0.8]  ← 隣接する値の差が制御される (0.8-0.5=0.3)
    # [0.5  0.8]  ← 全体で一貫したパターン
]
# 結果: 滑らかで一貫性のあるアップサンプリング
```

**3. 数学的説明**
- **最近傍補間との等価性**: ICNRは学習開始時に最近傍補間と同等の動作を実現
- **勾配の安定性**: 一貫した重みパターンにより、逆伝播時の勾配がより安定
- **周波数特性**: 高周波成分（チェッカーボードパターン）の生成を抑制

#### 重み配置パターンの解釈

上記の例では、PixelShuffle後の4つのsub-pixel位置は以下のように配置される：

```
Sub-pixel配置 (scale=2の場合):
位置0: 左上    → 入力チャンネル [0, 4] の重み
位置1: 右上    → 入力チャンネル [1, 5] の重み  
位置2: 左下    → 入力チャンネル [2, 6] の重み
位置3: 右下    → 入力チャンネル [3, 7] の重み

ICNRにより、各位置で同じ基本パターンが使用される:
- 位置0と位置2: 同じ重み (0.5, 0.8)
- 位置1と位置3: 同じ重み (0.5, 0.8)  
- 全位置で一貫したパターンにより滑らかなアップサンプリング
```

#### 効果的な改善例

```python
# 従来の初期化（ランダム）による問題:
# アップサンプリング結果が不規則なパターンを生成
[[1.2, 0.3, 2.1, 0.8],     # チェッカーボード状のアーティファクト
 [0.1, 1.9, 0.4, 2.3],     # 隣接ピクセル間の大きな値の変動
 [2.0, 0.6, 1.7, 0.2],
 [0.9, 2.4, 0.7, 1.5]]

# ICNR初期化による改善:
# 滑らかで一貫性のあるアップサンプリング結果
[[1.0, 1.2, 1.4, 1.6],     # 隣接ピクセル間の滑らかな遷移
 [1.1, 1.3, 1.5, 1.7],     # チェッカーボードパターンの大幅な抑制
 [1.2, 1.4, 1.6, 1.8],
 [1.3, 1.5, 1.7, 1.9]]
```

#### コードベース内での実装詳細

```python
class PixelShuffle_ICNR(nn.Sequential):
    def __init__(self, ni, nf=None, scale=2, blur=True):
        super().__init__()
        nf = ni if nf is None else nf
        layers = [nn.Conv2d(ni, nf*(scale**2), 1), LayerNorm2d(nf*(scale**2)), 
                  nn.GELU(), nn.PixelShuffle(scale)]
        # ICNR初期化の適用
        layers[0].weight.data.copy_(icnr_init(layers[0].weight.data))
        if blur: layers += [nn.ReplicationPad2d((1,0,1,0)), nn.AvgPool2d(2, stride=1)]
        super().__init__(*layers)
```

#### 理論的根拠
ICNRの効果は、畳み込み層とピクセルシャッフルの数学的関係に基づく。通常の最近傍補間と同等の初期状態を作り出すことで、学習開始時から滑らかなアップサンプリングが可能となり、最適化プロセスがより安定する。

#### 実用上の利点
- **学習初期の安定性向上**: チェッカーボードアーティファクトの除去により、勾配流がより安定
- **収束速度の向上**: 適切な初期状態により、より少ないエポック数での収束が可能
- **視覚的品質の向上**: 最終的な出力画像の視覚的品質が大幅に改善

## アーキテクチャでの活用

### U-Net デコーダブロック
`UnetBlock` において、ピクセルシャッフルはアップサンプリング操作として使用される：

```python
class UnetBlock(nn.Module):
    def __init__(self, up_in_c:int, x_in_c:int, nf:int=None, blur:bool=False, **kwargs):
        super().__init__()
        self.shuf = PixelShuffle_ICNR(up_in_c, up_in_c//2, blur=blur, **kwargs)
        # ... その他の初期化
        
    def forward(self, up_in:torch.Tensor, left_in:torch.Tensor) -> torch.Tensor:
        up_out = self.shuf(up_in)  # ピクセルシャッフルによるアップサンプリング
        # ... 残りの処理
```

### 最終出力ブロック
`UpBlock` では、最終的な解像度調整にピクセルシャッフルを使用：

```python
class UpBlock(nn.Module):
    def __init__(self, up_in_c:int, nf:int=None, blur:bool=True, **kwargs):
        super().__init__()
        ni = up_in_c//4
        self.shuf = PixelShuffle_ICNR(up_in_c, ni, blur=blur, **kwargs)
        # ... 畳み込み層の定義
```

## 利点と特徴

### 計算効率性
- 転置畳み込みと比較して、パラメータ数を削減
- メモリ使用量の最適化
- 推論速度の向上

### 品質向上
- ICNR初期化によるチェッカーボードアーティファクトの抑制
- オプションのブラー処理による滑らかな出力
- 学習可能なアップサンプリングによる適応的な特徴抽出

### 実装上の利点
- PyTorchの標準機能 `nn.PixelShuffle` を活用
- モジュラーな設計による再利用性
- 様々なスケールファクターへの対応

## コントレイル検出での応用
本プロジェクトでは、衛星画像からのコントレイル検出において、セグメンテーションマスクの高解像度復元にピクセルシャッフルアップスケーリングを活用している。特に、多スケール特徴融合と組み合わせることで、細かなコントレイル構造の正確な検出を実現している。

### 実践的な使用例

#### SAMモデルでの具体的な適用
```python
# SAM_UV2クラスでの実際の使用例
class SAM_UV2(nn.Module):
    def __init__(self, ...):
        # デコーダブロックでPixelShuffleを使用
        self.dec4 = UnetBlock(768, 512, 384)  # 768→384チャンネル, 2倍解像度
        self.dec3 = UnetBlock(384, 256, 192)  # 384→192チャンネル, 2倍解像度
        self.dec2 = UnetBlock(192, 32, 96)    # 192→96チャンネル, 2倍解像度
        
        # 最終出力でも使用
        self.final_conv = nn.Sequential(UpBlock(128, 1, blur=True))
        
    def forward(self, x):
        # 入力: (B, 3, 256, 256) の衛星画像
        # エンコーダ出力: [(B, 32, 256, 256), (B, 256, 128, 128), 
        #                 (B, 512, 64, 64), (B, 768, 32, 32)]
        
        # デコーダでの段階的アップサンプリング:
        # dec4: (B, 768, 32, 32) → (B, 384, 64, 64)
        # dec3: (B, 384, 64, 64) → (B, 192, 128, 128) 
        # dec2: (B, 192, 128, 128) → (B, 96, 256, 256)
        
        # 最終出力: (B, 1, 256, 256) のコントレイルマスク
```

#### 解像度復元の効果
```
低解像度特徴マップ (32×32) でのコントレイル検出:
[0, 0, 0.1, 0, 0]    →    高解像度マスク (256×256) での精密検出:
[0, 0.2, 0.8, 0.1, 0]    [0, 0, 0, 0.05, 0.1, 0, 0, 0]
[0, 0, 0.3, 0, 0]         [0, 0.1, 0.2, 0.4, 0.6, 0.2, 0.1, 0]
                          [0.05, 0.3, 0.7, 0.9, 0.8, 0.4, 0.1, 0]
                          [0, 0.2, 0.5, 0.7, 0.6, 0.3, 0, 0]
                          [0, 0, 0.1, 0.3, 0.2, 0.1, 0, 0]
                          [0, 0, 0, 0.1, 0.05, 0, 0, 0]
                          [0, 0, 0, 0, 0, 0, 0, 0]
```

## 参考文献
- Shi et al. "Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network" (2016)
- Aitken et al. "Checkerboard artifact free sub-pixel convolution" (2017)