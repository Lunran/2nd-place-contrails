https://www.kaggle.com/competitions/google-research-identify-contrails-reduce-global-warming/writeups/dit-2nd-place-solution

2nd place solution
Google Research - Identify Contrails to Reduce Global Warming
Solution Writeup · 2nd place · Aug 20, 2023

## 概要 (Summary)

- **ネットワーク**: CoaT、NeXtViT、SAM-B、tf_efficientnetv2_s バックボーンを使用したカスタマイズされたU字型ネットワーク
- **解像度**: ×2（256×256への予測のピクセルシャッフルアップスケーリング）および×4入力アップスケーリングで、予測のピクセルレベル精度が重要
- **時系列処理**: LSTM、Transformer、畳み込み時間混合による画像シーケンス処理
- **データ拡張**: マスクがシフトしているため、フリップと90度回転拡張（およびTTA）は使用せず
- **ラベル**: 全アノテーターの平均値であるソフトラベルで学習
- **損失関数**: BCE + dice Lovász loss

### コード

- **主要部分**: [My and @drhabib 's part](リンク) （最高性能のCoaT_ULSTMモデルを含む）
- **@theoviel's part**: [リンク](リンク)
- **推論**: [Inference](リンク)

## はじめに (Introduction)

私たちのチームは、この競技を可能にしてくださった主催者とKaggleに感謝いたします。また、最終結果に向けた素晴らしい貢献をしてくれた優秀なチームメイト @drhabib と @theoviel に感謝の意を表します。

## 詳細 (Details)

この競技には2つの主要な課題があります：

### 1. ノイズの多いラベル
アノテーター全員による注釈を確認すると、大きな意見の相違が明確に現れています。このラベルノイズの課題は、学習時にソフトラベル（全アノテーターラベルの平均）を使用することで部分的に対処できます。しかし、評価にはハードラベルが必要なため、主要なモデルの失敗は決定境界近くの飛行機雲の予測であり、これは避けることができません。

### 2. ピクセルレベル精度の要求
モデルによって実際に対処できることは、予測のピクセルレベル精度を達成することです。飛行機雲は数ピクセルの厚さしかないため、ピクセルレベル精度は非常に重要であり、横方向のマスク境界で1ピクセルの間違いでも、メトリックとして使用されるdiceスコアの大幅な低下を引き起こす可能性があります。

このようなタスクの典型的な解決策は、モデルの入力をアップサンプリングするか、セグメンテーションモデルの最終線形アップサンプリングを転置畳み込みまたはピクセルシャッフルアップサンプリングに置き換えることです。この修正により、元の解像度でのモデルの直接使用に比べて、初期実験で大幅な改善が得られました。

## データ (Data)

主催者の公開資料に従い、12μmバンド、12μmと11μmバンドの差、11μmと8μmバンドの差をそれぞれ考慮した「ash」偽色画像を使用しました。全バンドの考慮や、8、10、12μmでの「ash」カラー画像の拡張も試みましたが、性能が低下しました（最初の畳み込みの事前学習重みが複製されました）。ash色画像の最高性能は、アノテーターによるash色画像の使用と偏ったラベルノイズの結果である可能性があります。

実験では、入力をバイキュービック補間で以下のようにアップサンプリングしました：
- **CoaT・NeXtViTモデル**: ×2
- **SAMモデル**: ×4  
- **EfficientNetモデル**: 元の入力を使用するが、最初の畳み込みブロックのストライドを1に設定（×4入力アップサンプリングと同等）

## モデル (Model)

この競技の興味深い点は、モデルが以下の両方を実行する必要があることです：

1. **グローバルピクセル依存性の追跡**: 飛行機雲は非常に細長いため
2. **ピクセルレベル精度での予測生成**: 飛行機雲は数ピクセルの厚さしかないため

（1）はTransformerで対処でき、（2）は畳み込みネットワークまたはローカルアテンションで対処できます。競技では、SAM-B ViTバックボーンとEfficientNet v2純粋畳み込みネットワークでこれらの点を独立して対処しました。

さらに、階層構造を持つTransformerのクラスがあり、これは考慮された問題の両方の側面（1）+（2）を同時に対処します。このクラスには以下が含まれます：
- **CoaT**: 実験で最高の単一モデル性能を達成
- **NeXtViT**
- **MaxViT**（見逃しました）
- **SegformerのMiT transformer**（ライセンスの問題で競技では使用不可）

### デコーダー

以下のいずれかを考慮しました：
- **バニラU-Netデコーダー**（EfficientNetモデル）
- **カスタマイズされたU-ブロックセット**（CoaT、NeXtViT、SAM）：ピクセルシャッフルアップサンプリングと因数分解FPNを使用

これらのブロックでは、低バッチサイズでの適切なモデル収束のためにBatchNormをLayerNorm2dに置き換え、ReLUの代わりにGELU活性化を使用しました。

モデルの概略図を以下に示します。

![モデル概略図]

## 時間的ミキシング (Temporal mixing)

単一フレームモデルでの初期実験に加えて、画像シーケンスを用いた実験も実施しました。最適な設定では、マルチフレームモデルは約0.01の改善を達成しました。

画像が相当な時間遅延で撮影されており、フレーム間での雲の変位が非常に大きく（約10-30ピクセル）、入力のアップサンプリングによってさらに悪化するため、3D畳み込みやウィンドウアテンション（VideoSwin）に基づく動画モデルは、考慮された問題の文脈では効果的ではありません。同様の理由で、早期ミキシングや連続モデルの予測のミキシングも効果的でないと予想されます。したがって、res/32やres/16などの中間特徴マップスケールでのミキシングが最も有望です：雲/飛行機雲が位置ずれしていても、低解像度での特徴マップは合理的に整列されています。CoaTモデルでの実験では、2つの低解像度特徴マップ（res/32とres/16）を考慮した場合に最高性能が達成されました。時間的ミキシングモジュールの出力と残りの特徴マップの出力は、フレーム4でプールされ、デコーダーは考慮されたフレームに対応する入力のみを見ます（図1に示すとおり）。

時間的ミキシングモジュールとして、LSTM（最高性能を達成）、1D時間畳み込み、およびTransformerを検討しました。LSTM（1層）と1D時間畳み込みは時間次元のみでミキシングを実行し、特徴間の空間依存性はバックボーンとデコーダーで考慮されます。Transformerベースのミキシングは、飛行機雲/雲の大きな変位に対する暗黙的特徴マップ登録を実行するために提案されました。これは時間的および空間的特徴ミキシングを同時に動作させ、空間的に整列していなくてもマッチングできるためです。

このミキシングは以下の方法で実行されます。与えられたフレームに対応する各特徴マップに、他と区別するためのエンコーディングを追加し、すべてのフレームからのトークンを単一シーケンスに平坦化し、2つのトランスフォーマーデコーダーブロックで処理します。トランスフォーマーへのキーと値の入力は、すべてのフレームの連結シーケンスで表現され、クエリは第4フレームのみのトークンシーケンスです。残念ながら、Transformerベースのミキシングはわずかに性能が低く、それを用いた訓練はより不安定でした。しかし、改善された多様性の恩恵を受けるため、最終アンサンブルでは両方のアプローチを保持しました。

CoaT/NeXtViTでの実験では、主催者の出版物に従い、最初の5フレームを入力として選択しました。LSTMとTransformerミキシングの両方が検討されました。EfficientNetでの実験では、双方向LSTMを用いて4フレーム入力（2番目〜5番目、注釈フレームの前後2フレームと1フレーム）を検討しました。このフレーム選択は、少なくとも2つの連続フレームで飛行機雲を持つというアノテーターへの指示によって決定されます。SAMモデルでは、このモデルの重いVRAM要件のため、3フレーム（注釈の前後1フレームずつ）での1D畳み込みミキシングを検討しました。これは推論でも問題となりました。

フレーム間で飛行機雲と雲を整列させるために入力フレームの明示的登録を行うアイデアがありました（時間的ミキシングが最も効果的）。例えばオプティカルフローの考慮です。残念ながら、画像には雲だけでなく動かない地球表面や、異なる方向に移動する複数の雲層も含まれています。したがって、フレーム登録タスクを進める方法を考案できませんでした。予測された飛行機雲に基づく登録も検討しましたが、飛行機雲はフレーム間で出現・消失するため、このアプローチも実現可能ではありませんでした。

## 疑似ラベル (Pseudo-labels, PL)

競技データに加えて、「Contrails GOES16 Images May」データセット（単一フレーム設定）[9]を収集しました。画像を部分的に重複した256×256タイルに分割し、最良の単一フレームモデルのアンサンブルに基づいてマスクを生成しました。このデータはKaggleデータセット[10]として共有されています。このデータは一部の実験において単一フレーム設定でのモデル事前学習に使用され、その後単一フレームまたはマルチフレーム設定でモデルをファインチューニングしました。PLの使用により個別モデル（フォールド）の性能は大幅に改善されましたが、ファインチューニングされたモデルの各フォールドが独立して訓練されたPLモデルを使用してもモデルの多様性は減少しました。したがって、全フォールドでの平均予測の性能は、PLなしで訓練された設定と同等でした。

また、外部データと未注釈の競技フレームの両方でのPL訓練も実験しましたが、単一フレームモデルのファインチューニングには何らかの利益を与えませんでした。このような事前学習がマルチフレームモデルに影響を与える可能性があるため、本格実験ではPLステップで外部データのみを使用しました。

## 学習 (Training)

**CoaTとNeXtViTモデル**: 学習は24エポックにわたって実行され、Over9000（Radam+LAMB+LookAhead）オプティマイザー、学習率3.5e-4、重み減衰0.01を使用しました。このオプティマイザーがCoaTとの優れた互換性を持つことが判明しました。PL事前学習の場合、外部データで12エポック実行し、その後CoaTモデルは12エポック、NeXtViTモデルは18エポックでファインチューニングを行いました。

**EfficientNetモデル**: 事前学習は単一フレーム設定で100エポック実行され、追加のCutMix拡張、学習率1e-3、AdamWオプティマイザー、重み減衰0.2を使用しました。事前学習中、PLデータの割合は線形に0まで減少させました。その後、画像シーケンス設定でモデルをファインチューニングし、エンコーダーに3e-5、デコーダーに1e-4の学習率を使用しました。事前学習への外部データの追加により、はるかに強力な2Dモデルが得られたため、マルチフレームEfficientNetモデルは最終アンサンブルでは考慮されませんでした。多様性のため、200エポックでの事前学習と、full-fit設定（検証セットを含むすべてのデータでの学習）でのモデルも事前学習しました。

**SAMモデル**: 最終提出には単一フレームのSAM-B ViTベースモデルのみを含めました。学習中は、まず凍結されたエンコーダーでモデルを10エポック学習し、その後モデルを解凍してさらに20エポック継続しました。AdamWオプティマイザーを使用し、エンコーダーに4e-6、デコーダーに4e-5の学習率を設定しました。

学習中は、ShiftRotateScale、RandomGamma、RandomBrightnessContrast、MotionBlur、GaussianBlur拡張を使用しました。Flipと90度回転拡張は性能悪化を引き起こすため使用しませんでした。すべての本格モデルの学習は5-6フォールドで実行され、フォールドは異なるランダムシードで全訓練データセットで学習し、評価は提供された検証セットで実行しました。この戦略は、訓練データの標準的なK-fold分割での評価がCV（交差検証）を過大評価するために使用されており、これは訓練データセット内のタイルの空間的重複が原因である可能性があります。

## 損失関数 (Loss)

損失関数として、BCE + dice Lovász損失を使用しました。第2項は修正版Lovász損失[12]で、(1) ReLUを1 + ELUに置換、(2) 対称バージョンを使用、(3) IoUの代わりにdiceを最大化する代理関数を使用しています。第2項は個別モデル性能に軽微な向上をもたらします。しかし、この項は閾値選択に対するdiceのより広い最大値を与え、すなわち閾値選択に対する性能の依存性をより弱くします。この特性は、不適切な閾値によるプライベートリーダーボードでのシェイクアップを回避するために重要であり、より効果的なアンサンブルにとって好ましいものです。

## 結果 (Results)

最終モデルの性能を以下の表にまとめました。Exは PL設定で訓練されたモデルを指します（EfficientNetはPLのみで訓練）。接尾辞Uは単一フレームモデル、UT はTransformerベースの時間的ミキシング、ULSTMはLSTMベースの時間的ミキシングを指します。閾値はCV値を最大化する検索に基づいて選択されました。ほとんどのモデルで0.46-0.50でした。

### 最良単一モデル

最良の単一モデルはCoaTで、5フォールドで0.7039 CV、0.71790 private、0.71243 public LBを達成しました。単一フォールドCVは検証セットで評価した0.6960±0.0003です（訓練データの標準的なK-fold分割での評価は、空間的重複の可能性によりCVを過大評価するため、フォールドは異なるシードで訓練セットで訓練されます）。この単一モデルだけで競技のトップ4に入ることができました。

### アンサンブル

最良のアンサンブルは8モデルで構成され、すべてのコンポーネントからほぼ等しい貢献をするように重みが選択されています：CV は0.7140（評価セット）、0.72574 public、0.72304 private LBです。モデルとその重みを以下の表にまとめました。

EfficientNetには3つのモデル設定（100エポック、200エポック、full-fit）が含まれ、total efficient weightは1に等しくなります。

## モデル実行時間 (Model Execution Time)

**CoaTとNeXtViTモデル**: 学習時間は2×RTX4090 GPUでフォールドあたり単一フレーム2時間、マルチフレーム8時間です。Kaggle（P100）でのマルチフレームモデルの推論時間は5フォールドで35分です。

**EfficientNetモデル**: 学習時間は8×V100 GPUでフォールドあたり100エポックで3時間45分です。Kaggle（P100）での推論は、データ読み込みを含めて6フォールドで20分です。

**SAMモデル**: 学習時間は2×A6000 GPUでフォールドあたり16時間です。Kaggle（P100）での推論は、データ読み込みを含めて5フォールドで48分です。

## 見逃した点 (Things we missed)

**(1)** 競技中、モデル学習でのFlipと90度回転拡張が性能悪化を引き起こすという驚くべき発見がありました。これは非常に驚きでしたが、残念ながらこの現象の起源について十分に考察せず、卓越風と雲・飛行機雲の特有の形状に起因するものと考えていました。競技後、マスクが0.5ピクセルずれていることが判明し、これが発見した通りFlip処理を適用不可能にしていました。もしマスクの問題が設定で修正されていれば、Flip/90度回転拡張により効果的な訓練データセットサイズが8倍に増加し、テスト時拡張によって推論段階でのさらなる性能向上が可能になります。したがって、潜在的にモデルの性能は著しく改善される可能性があります。

**(2)** 外部データでのPL単一モデル事前学習は、単一フレームモデルに適度なCV改善を与えます（興味深いことに、プライベートLBでこの改善は非常に大きいです）。一方、この単一フレーム事前学習はシーケンスモデルにはあまり効果を与えませんでした。したがって、外部シーケンスデータの収集と適切な再投影が、シーケンスモデルにとってより良い事前学習戦略として機能する可能性があり、単一フレームモデルに匹敵する向上が期待できます。
